{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c82c280",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook is for EDA and first cleaning only.\n",
    "\n",
    "It does **not** train models.\n",
    "\n",
    "Goal:\n",
    "- understand data quality\n",
    "- check distributions and seasonality\n",
    "- create a clean feature table for later modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e01ad0",
   "metadata": {},
   "source": [
    "## Step 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8990f855",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\nROOT = Path.cwd()\nFEATURE_PATH = ROOT / \"Data\" / \"processed\" / \"zh_monthly_features.parquet\"\nSITES_PATH = ROOT / \"Data\" / \"processed\" / \"zh_sites.parquet\"\n\nif not FEATURE_PATH.exists() or not SITES_PATH.exists():\n    raise FileNotFoundError(\"Run Data/datasets.ipynb first to create processed files.\")\n\ndf = pd.read_parquet(FEATURE_PATH)\nsites = pd.read_parquet(SITES_PATH)\n\ndf[\"month\"] = pd.to_datetime(df[\"month\"])\n\nprint(\"features shape:\", df.shape)\nprint(\"sites shape:\", sites.shape)\nprint(\"date range:\", df[\"month\"].min().date(), \"->\", df[\"month\"].max().date())\nprint(\"number of sites:\", df[\"site_id\"].nunique())"
  },
  {
   "cell_type": "markdown",
   "id": "3e88724c",
   "metadata": {},
   "source": [
    "## Step 2: Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b0c46",
   "metadata": {},
   "outputs": [],
   "source": "print(\"Columns:\")\nprint(df.columns.tolist())\n\nprint()\nprint(\"Duplicate site-month rows:\", int(df.duplicated([\"site_id\", \"month\"]).sum()))\n\nmissing_pct = (df.isna().mean() * 100).sort_values(ascending=False)\nprint()\nprint(\"Missing rate (%):\")\nprint(missing_pct.round(2).astype(str) + \"%\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b85a6",
   "metadata": {},
   "outputs": [],
   "source": "# Missingness by site for meteo\nmeteo_cols = [\"tp_mm\", \"pet_mm\", \"t2m_c\"]\nsite_meteo_missing = (\n    df.groupby(\"site_id\")[meteo_cols]\n    .apply(lambda x: x.isna().mean().mean())\n    .rename(\"meteo_missing_ratio\")\n    .reset_index()\n)\n\nprint(\"Site-level meteo missing ratio counts:\")\nprint(site_meteo_missing[\"meteo_missing_ratio\"].value_counts().sort_index())\n\nsites_all_meteo_missing = set(\n    site_meteo_missing.loc[site_meteo_missing[\"meteo_missing_ratio\"] == 1.0, \"site_id\"].tolist()\n)\nprint()\nprint(\"Sites with all meteo missing:\", len(sites_all_meteo_missing))\nprint(\"Sites with usable meteo:\", df[\"site_id\"].nunique() - len(sites_all_meteo_missing))\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaea6bc",
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(7, 3.8))\nmissing_pct.sort_values(ascending=False).plot(kind=\"bar\", ax=ax)\nax.set_ylabel(\"Missing (%)\")\nax.set_title(\"Missing Rate by Column\")\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "70cd1d08",
   "metadata": {},
   "source": [
    "## Step 3: Distribution checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c361c",
   "metadata": {},
   "outputs": [],
   "source": "num_cols = [\"tp_mm\", \"pet_mm\", \"t2m_c\", \"spi3_z\", \"spi6_z\", \"spi12_z\", \"pumping_m3_month\"]\nsummary = df[num_cols].describe(percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]).T\nprint(summary[[\"mean\", \"std\", \"min\", \"1%\", \"5%\", \"50%\", \"95%\", \"99%\", \"max\"]])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232aba80",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 3, figsize=(14, 3.8))\n\ndf[\"tp_mm\"].dropna().hist(ax=axes[0], bins=40)\naxes[0].set_title(\"tp_mm\")\n\n\ndf[\"t2m_c\"].dropna().hist(ax=axes[1], bins=40)\naxes[1].set_title(\"t2m_c\")\n\nclip_99 = df[\"pumping_m3_month\"].quantile(0.99)\ndf[\"pumping_m3_month\"].clip(upper=clip_99).hist(ax=axes[2], bins=40)\naxes[2].set_title(\"pumping_m3_month (clip 99%)\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "2612d107",
   "metadata": {},
   "source": [
    "## Step 4: Time patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea1769",
   "metadata": {},
   "outputs": [],
   "source": "# Monthly average over all sites\nmonthly_avg = (\n    df.groupby(\"month\")[[\"tp_mm\", \"pet_mm\", \"t2m_c\", \"pumping_m3_month\"]]\n    .mean()\n    .sort_index()\n)\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 6), sharex=True)\nmonthly_avg[\"tp_mm\"].plot(ax=axes[0, 0], title=\"Mean tp_mm\")\nmonthly_avg[\"pet_mm\"].plot(ax=axes[0, 1], title=\"Mean pet_mm\")\nmonthly_avg[\"t2m_c\"].plot(ax=axes[1, 0], title=\"Mean t2m_c\")\nmonthly_avg[\"pumping_m3_month\"].plot(ax=axes[1, 1], title=\"Mean pumping_m3_month\")\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9346b6",
   "metadata": {},
   "outputs": [],
   "source": "# Calendar month seasonality\ntmp = df.copy()\ntmp[\"cal_month\"] = tmp[\"month\"].dt.month\nseason = tmp.groupby(\"cal_month\")[[\"tp_mm\", \"pet_mm\", \"t2m_c\"]].mean()\n\nfig, ax = plt.subplots(figsize=(8, 4))\nseason.plot(ax=ax)\nax.set_title(\"Seasonality by Calendar Month\")\nax.set_xlabel(\"Month\")\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "f8d7d486",
   "metadata": {},
   "source": [
    "## Step 5: Feature relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae97759",
   "metadata": {},
   "outputs": [],
   "source": "corr_cols = [\"tp_mm\", \"pet_mm\", \"t2m_c\", \"spi3_z\", \"spi6_z\", \"spi12_z\", \"pumping_m3_month\"]\ncorr = df[corr_cols].corr(numeric_only=True)\nprint(corr.round(3))\n\nfig, ax = plt.subplots(figsize=(7, 5))\nim = ax.imshow(corr.values, cmap=\"coolwarm\", vmin=-1, vmax=1)\nax.set_xticks(range(len(corr_cols)))\nax.set_yticks(range(len(corr_cols)))\nax.set_xticklabels(corr_cols, rotation=45, ha=\"right\")\nax.set_yticklabels(corr_cols)\nax.set_title(\"Correlation Matrix\")\nplt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "697fd0ae",
   "metadata": {},
   "source": [
    "## Step 6: First cleaning for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d312ea",
   "metadata": {},
   "outputs": [],
   "source": "work = df.copy()\n\n# 1) drop site-level ERA5 metadata\ndrop_cols = [\"number\", \"latitude\", \"longitude\", \"expver\"]\nwork = work.drop(columns=[c for c in drop_cols if c in work.columns])\n\n# 2) remove sites with all meteo missing\nwork = work[~work[\"site_id\"].isin(sites_all_meteo_missing)].copy()\n\n# 3) remove rows with missing hydro features\nwork = work[work[\"tp_mm\"].notna() & work[\"pet_mm\"].notna() & work[\"t2m_c\"].notna()].copy()\n\n# 4) remove SPI warm-up rows\nwork = work[work[\"spi12_z\"].notna()].copy()\n\n# 5) pumping transform\nwork[\"pumping_m3_month\"] = work[\"pumping_m3_month\"].clip(lower=0)\nwork[\"pumping_m3_month_log1p\"] = np.log1p(work[\"pumping_m3_month\"])\n\n# 6) month cyclical encoding\nwork[\"month_sin\"] = np.sin(2 * np.pi * work[\"month\"].dt.month / 12.0)\nwork[\"month_cos\"] = np.cos(2 * np.pi * work[\"month\"].dt.month / 12.0)\n\nwork = work.sort_values([\"site_id\", \"month\"]).reset_index(drop=True)\n\nsites_clean = sites[sites[\"site_id\"].isin(work[\"site_id\"].unique())].copy()\n\nprint(\"clean feature shape:\", work.shape)\nprint(\"clean sites shape:\", sites_clean.shape)\nprint(\"clean date range:\", work[\"month\"].min().date(), \"->\", work[\"month\"].max().date())\nprint(\"clean site count:\", work[\"site_id\"].nunique())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f345f4",
   "metadata": {},
   "outputs": [],
   "source": "# Feature groups for your ablation design\nfeature_sets = {\n    \"hydro_only\": [\"tp_mm\", \"pet_mm\", \"t2m_c\"],\n    \"hydro_plus_pumping\": [\"tp_mm\", \"pet_mm\", \"t2m_c\", \"pumping_m3_month_log1p\"],\n    \"hydro_plus_pumping_plus_spi\": [\"tp_mm\", \"pet_mm\", \"t2m_c\", \"pumping_m3_month_log1p\", \"spi3_z\", \"spi6_z\", \"spi12_z\"],\n}\n\nfor k, v in feature_sets.items():\n    print(k, \"->\", v)"
  },
  {
   "cell_type": "markdown",
   "id": "d82eee5a",
   "metadata": {},
   "source": [
    "## Step 7: Save EDA outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6155f",
   "metadata": {},
   "outputs": [],
   "source": "out_dir = ROOT / \"Data\" / \"processed\"\nout_dir.mkdir(parents=True, exist_ok=True)\n\nfeat_out = out_dir / \"zh_features_model_ready.parquet\"\nsite_out = out_dir / \"zh_sites_model_ready.parquet\"\n\nsaved_feat = None\nsaved_site = None\n\ntry:\n    work.to_parquet(feat_out, index=False)\n    sites_clean.to_parquet(site_out, index=False)\n    saved_feat, saved_site = feat_out, site_out\nexcept Exception:\n    feat_out = out_dir / \"zh_features_model_ready.pkl\"\n    site_out = out_dir / \"zh_sites_model_ready.pkl\"\n    work.to_pickle(feat_out)\n    sites_clean.to_pickle(site_out)\n    saved_feat, saved_site = feat_out, site_out\n\nprint(\"Saved:\")\nprint(\"-\", saved_feat)\nprint(\"-\", saved_site)\nprint(work.head())"
  },
  {
   "cell_type": "markdown",
   "id": "8139d840",
   "metadata": {},
   "source": [
    "## Status vs your thesis design\n",
    "\n",
    "What is done now:\n",
    "- EDA is done.\n",
    "- Hydro, pumping, and SPI features are prepared.\n",
    "- A clean feature table is saved for modeling.\n",
    "\n",
    "What is not done yet:\n",
    "- target variable (`y_anomaly`, SGI-like) is still missing.\n",
    "- train/validation/test with target is not built yet.\n",
    "- model training and evaluation are not done yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}