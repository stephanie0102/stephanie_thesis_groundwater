{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e616f0",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook prepares data for the thesis.\n",
    "\n",
    "We use only these files for now:\n",
    "- `brogmkenset.gpkg`\n",
    "- `bro_groundwater_use.gpkg`\n",
    "- `era5_land_monthly.nc`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac464b83",
   "metadata": {},
   "source": [
    "## Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e095cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using files:\n",
      "- /Users/izhan/Desktop/groundwater/stephanie_thesis_groundwater/Data/raw/brogmkenset.gpkg\n",
      "- /Users/izhan/Desktop/groundwater/stephanie_thesis_groundwater/Data/raw/bro_groundwater_use.gpkg\n",
      "- /Users/izhan/Desktop/groundwater/stephanie_thesis_groundwater/Data/raw/era5_land_monthly.nc\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import fiona\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "\n",
    "MONITOR_GPKG = ROOT / \"Data\" / \"raw\" / \"brogmkenset.gpkg\"\n",
    "USE_GPKG = ROOT / \"Data\" / \"raw\" / \"bro_groundwater_use.gpkg\"\n",
    "ERA5_NC = ROOT / \"Data\" / \"raw\" / \"era5_land_monthly.nc\"\n",
    "\n",
    "for p in [MONITOR_GPKG, USE_GPKG, ERA5_NC]:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing file: {p}\")\n",
    "\n",
    "print(\"Using files:\")\n",
    "print(\"-\", MONITOR_GPKG)\n",
    "print(\"-\", USE_GPKG)\n",
    "print(\"-\", ERA5_NC)\n",
    "\n",
    "\n",
    "def read_table_gpkg(gpkg_path: Path, layer: str) -> pd.DataFrame:\n",
    "    # Read a non-spatial GPKG table as pandas DataFrame (no SQL).\n",
    "    # Fiona may omit primary key columns in properties, so we recover them from feat.id.\n",
    "    rows = []\n",
    "    pk_col = f\"{layer}_pk\"\n",
    "\n",
    "    with fiona.open(gpkg_path, layer=layer) as src:\n",
    "        for feat in src:\n",
    "            rec = dict(feat[\"properties\"])\n",
    "            fid = feat.get(\"id\")\n",
    "            if fid is not None:\n",
    "                try:\n",
    "                    rec[\"_fid\"] = int(fid)\n",
    "                except Exception:\n",
    "                    rec[\"_fid\"] = fid\n",
    "            rows.append(rec)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if pk_col not in df.columns and \"_fid\" in df.columns:\n",
    "        df[pk_col] = df[\"_fid\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def require_columns(df: pd.DataFrame, required: list[str], name: str) -> None:\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"{name} is missing columns: {missing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff24972",
   "metadata": {},
   "source": [
    "## Select monitoring sites in ZH\n",
    "\n",
    "Rule:\n",
    "- inside rough ZH bbox\n",
    "- enough records (`max_observations >= 120`)\n",
    "- long time coverage (`first_date <= 2010-01-01`, `last_date >= 2025-01-01`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b4a3d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tubes with series: 94182\n",
      "ZH candidate tubes: 649\n",
      "ZH candidate wells: 351\n",
      "      site_id  well_id  max_observations first_date  last_date\n",
      "5652     9708     8538               158 1997-09-15 2025-10-01\n",
      "5653     9709     8538               354 1997-09-15 2025-10-01\n",
      "5664     9722     8546               196 1993-03-18 2025-09-25\n",
      "5665     9723     8546               196 1993-03-18 2025-09-25\n",
      "5670     9728     8549               442 1987-01-14 2025-09-25\n"
     ]
    }
   ],
   "source": [
    "# Load monitoring layers\n",
    "# Note: some environments do not expose FID columns (like *_pk) as normal columns.\n",
    "tubes = gpd.read_file(MONITOR_GPKG, layer=\"gm_gmw_monitoringtube\")\n",
    "series = gpd.read_file(MONITOR_GPKG, layer=\"gm_gld\")\n",
    "\n",
    "if \"gm_gmw_monitoringtube_pk\" not in tubes.columns:\n",
    "    tubes = tubes.reset_index().rename(columns={\"index\": \"gm_gmw_monitoringtube_pk\"})\n",
    "\n",
    "require_columns(tubes, [\"gm_gmw_monitoringtube_pk\", \"gm_gmw_fk\", \"geometry\"], \"gm_gmw_monitoringtube\")\n",
    "require_columns(series, [\"gm_gmw_monitoringtube_fk\", \"research_first_date\", \"research_last_date\", \"number_of_observations\"], \"gm_gld\")\n",
    "\n",
    "# Parse dates\n",
    "series[\"research_first_date\"] = pd.to_datetime(series[\"research_first_date\"], errors=\"coerce\")\n",
    "series[\"research_last_date\"] = pd.to_datetime(series[\"research_last_date\"], errors=\"coerce\")\n",
    "series[\"number_of_observations\"] = pd.to_numeric(series[\"number_of_observations\"], errors=\"coerce\")\n",
    "\n",
    "# One metadata row per tube\n",
    "# Use size() so we do not depend on gm_gld_pk being present.\n",
    "series_by_tube = (\n",
    "    series.groupby(\"gm_gmw_monitoringtube_fk\", as_index=False)\n",
    "    .agg(\n",
    "        n_series=(\"gm_gmw_monitoringtube_fk\", \"size\"),\n",
    "        max_observations=(\"number_of_observations\", \"max\"),\n",
    "        first_date=(\"research_first_date\", \"min\"),\n",
    "        last_date=(\"research_last_date\", \"max\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "sites = tubes[[\"gm_gmw_monitoringtube_pk\", \"gm_gmw_fk\", \"geometry\"]].copy()\n",
    "sites = sites.merge(\n",
    "    series_by_tube,\n",
    "    left_on=\"gm_gmw_monitoringtube_pk\",\n",
    "    right_on=\"gm_gmw_monitoringtube_fk\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "sites = sites.rename(columns={\n",
    "    \"gm_gmw_monitoringtube_pk\": \"site_id\",\n",
    "    \"gm_gmw_fk\": \"well_id\",\n",
    "})\n",
    "\n",
    "# Rough ZH bbox (lon/lat)\n",
    "minx, maxx = 3.6, 5.1\n",
    "miny, maxy = 51.7, 52.3\n",
    "sites_zh = sites.cx[minx:maxx, miny:maxy].copy()\n",
    "\n",
    "# Keep strong candidate sites\n",
    "sites_zh = sites_zh[\n",
    "    (sites_zh[\"max_observations\"] >= 120)\n",
    "    & (sites_zh[\"first_date\"] <= pd.Timestamp(\"2010-01-01\"))\n",
    "    & (sites_zh[\"last_date\"] >= pd.Timestamp(\"2025-01-01\"))\n",
    "].copy()\n",
    "\n",
    "if sites_zh.empty:\n",
    "    raise ValueError(\"No sites left after filtering. Relax bbox/date/observation rules.\")\n",
    "\n",
    "sites_zh[\"lon\"] = sites_zh.geometry.x\n",
    "sites_zh[\"lat\"] = sites_zh.geometry.y\n",
    "\n",
    "print(\"Total tubes with series:\", sites[\"site_id\"].nunique())\n",
    "print(\"ZH candidate tubes:\", sites_zh[\"site_id\"].nunique())\n",
    "print(\"ZH candidate wells:\", sites_zh[\"well_id\"].nunique())\n",
    "print(sites_zh[[\"site_id\", \"well_id\", \"max_observations\", \"first_date\", \"last_date\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc6eb1",
   "metadata": {},
   "source": [
    "## Prepare monthly ERA5 features for each site\n",
    "\n",
    "Features:\n",
    "- `tp_mm` (precipitation, mm/month)\n",
    "- `pet_mm` (potential evaporation, mm/month, positive direction)\n",
    "- `t2m_c` (2m temperature, Celsius)\n",
    "- `spi3_z`, `spi6_z`, `spi12_z` (simple SPI-like z-score from rolling precipitation sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e803c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meteo table shape: (124608, 12)\n",
      "       month  site_id  number  latitude  longitude expver     tp_mm    pet_mm  \\\n",
      "0 2010-01-01     9708       0      52.2        5.1   0001  1.420961  0.474006   \n",
      "1 2010-01-01     9709       0      52.2        5.1   0001  1.420961  0.474006   \n",
      "2 2010-01-01     9722       0      52.3        4.8   0001  1.577557  0.599541   \n",
      "3 2010-01-01     9723       0      52.3        4.8   0001  1.577557  0.599541   \n",
      "4 2010-01-01     9728       0      52.3        4.8   0001  1.577557  0.599541   \n",
      "\n",
      "      t2m_c  spi3_z  spi6_z  spi12_z  \n",
      "0 -0.712128     NaN     NaN      NaN  \n",
      "1 -0.712128     NaN     NaN      NaN  \n",
      "2 -0.161346     NaN     NaN      NaN  \n",
      "3 -0.161346     NaN     NaN      NaN  \n",
      "4 -0.161346     NaN     NaN      NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/izhan/opt/anaconda3/envs/thsis/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:2015: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/izhan/opt/anaconda3/envs/thsis/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:2015: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/izhan/opt/anaconda3/envs/thsis/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:2015: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "# Time window used for model inputs\n",
    "MONTHS = pd.date_range(\"2010-01-01\", \"2025-12-01\", freq=\"MS\")\n",
    "\n",
    "# Load ERA5 monthly data\n",
    "era5 = xr.open_dataset(ERA5_NC)\n",
    "era5 = era5.sel(valid_time=slice(MONTHS.min(), MONTHS.max()))\n",
    "\n",
    "site_ids = sites_zh[\"site_id\"].astype(int).to_numpy()\n",
    "lon_da = xr.DataArray(\n",
    "    sites_zh.set_index(\"site_id\").loc[site_ids, \"lon\"].to_numpy(),\n",
    "    dims=[\"site_id\"],\n",
    "    coords={\"site_id\": site_ids},\n",
    ")\n",
    "lat_da = xr.DataArray(\n",
    "    sites_zh.set_index(\"site_id\").loc[site_ids, \"lat\"].to_numpy(),\n",
    "    dims=[\"site_id\"],\n",
    "    coords={\"site_id\": site_ids},\n",
    ")\n",
    "\n",
    "# Nearest ERA5 grid cell for each site\n",
    "meteo = xr.Dataset(\n",
    "    {\n",
    "        \"tp_mm\": era5[\"tp\"].sel(longitude=lon_da, latitude=lat_da, method=\"nearest\") * 1000.0,\n",
    "        \"pet_mm\": -era5[\"pev\"].sel(longitude=lon_da, latitude=lat_da, method=\"nearest\") * 1000.0,\n",
    "        \"t2m_c\": era5[\"t2m\"].sel(longitude=lon_da, latitude=lat_da, method=\"nearest\") - 273.15,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Simple SPI-like z-score from rolling precipitation sums\n",
    "for w in [3, 6, 12]:\n",
    "    p_roll = meteo[\"tp_mm\"].rolling(valid_time=w, min_periods=w).sum()\n",
    "    meteo[f\"spi{w}_z\"] = (p_roll - p_roll.mean(dim=\"valid_time\")) / (p_roll.std(dim=\"valid_time\") + 1e-6)\n",
    "\n",
    "meteo_df = meteo.to_dataframe().reset_index()\n",
    "meteo_df = meteo_df.rename(columns={\"valid_time\": \"month\"})\n",
    "meteo_df[\"month\"] = pd.to_datetime(meteo_df[\"month\"]).dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "print(\"Meteo table shape:\", meteo_df.shape)\n",
    "print(meteo_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa6f1e",
   "metadata": {},
   "source": [
    "## Build monthly pumping proxy (buffer-based)\n",
    "\n",
    "Method:\n",
    "1. Keep only `onttrekken` (abstraction) quantities.\n",
    "2. Convert quantity to annual volume (`annual_m3`).\n",
    "3. Link quantity to facility and validity period.\n",
    "4. For each site, sum active facilities in a 5 km buffer each month.\n",
    "\n",
    "This gives `pumping_m3_month`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b567f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facilities in ZH with positive annual quantity: 5808\n",
      "     groundwater_usage_facility_pk  annual_m3 valid_start  valid_end\n",
      "25                              22    25000.0  2023-03-23 2100-12-31\n",
      "50                              42  1071360.0  2023-03-14 2100-12-31\n",
      "91                              61   311000.0  2023-02-22 2100-12-31\n",
      "151                             93      567.0  2023-02-01 2023-03-06\n",
      "153                             95    12800.0  2022-06-06 2100-12-31\n"
     ]
    }
   ],
   "source": [
    "# Load facility geometry and tabular layers (no SQL)\n",
    "facilities = gpd.read_file(USE_GPKG, layer=\"groundwater_usage_facility\")\n",
    "if \"groundwater_usage_facility_pk\" not in facilities.columns:\n",
    "    facilities = facilities.reset_index().rename(columns={\"index\": \"groundwater_usage_facility_pk\"})\n",
    "require_columns(facilities, [\"groundwater_usage_facility_pk\", \"geometry\"], \"groundwater_usage_facility\")\n",
    "facilities = facilities[[\"groundwater_usage_facility_pk\", \"geometry\"]].copy()\n",
    "\n",
    "licence = read_table_gpkg(USE_GPKG, \"licence_groundwater_usage\")\n",
    "quantity = read_table_gpkg(USE_GPKG, \"licensed_quantity\")\n",
    "validity = read_table_gpkg(USE_GPKG, \"validity_period\")\n",
    "\n",
    "require_columns(licence, [\"licence_groundwater_usage_pk\", \"groundwater_usage_facility_fk\"], \"licence_groundwater_usage\")\n",
    "require_columns(\n",
    "    quantity,\n",
    "    [\n",
    "        \"licence_groundwater_usage_fk\",\n",
    "        \"licensed_in_out\",\n",
    "        \"maximum_per_hour\",\n",
    "        \"maximum_per_day\",\n",
    "        \"maximum_per_month\",\n",
    "        \"maximum_per_year\",\n",
    "    ],\n",
    "    \"licensed_quantity\",\n",
    ")\n",
    "require_columns(validity, [\"groundwater_usage_facility_fk\", \"start_validity\", \"end_validity\"], \"validity_period\")\n",
    "\n",
    "licence = licence[[\"licence_groundwater_usage_pk\", \"groundwater_usage_facility_fk\"]].copy()\n",
    "quantity = quantity[[\n",
    "    \"licence_groundwater_usage_fk\",\n",
    "    \"licensed_in_out\",\n",
    "    \"maximum_per_hour\",\n",
    "    \"maximum_per_day\",\n",
    "    \"maximum_per_month\",\n",
    "    \"maximum_per_year\",\n",
    "]].copy()\n",
    "validity = validity[[\"groundwater_usage_facility_fk\", \"start_validity\", \"end_validity\"]].copy()\n",
    "\n",
    "# Keep only abstraction rows\n",
    "quantity[\"licensed_in_out\"] = quantity[\"licensed_in_out\"].astype(str).str.lower().str.strip()\n",
    "quantity = quantity[quantity[\"licensed_in_out\"] == \"onttrekken\"].copy()\n",
    "\n",
    "# Numeric conversion\n",
    "for c in [\"maximum_per_hour\", \"maximum_per_day\", \"maximum_per_month\", \"maximum_per_year\"]:\n",
    "    quantity[c] = pd.to_numeric(quantity[c], errors=\"coerce\")\n",
    "\n",
    "# Build annual volume (fallback if maximum_per_year is missing)\n",
    "quantity[\"annual_m3\"] = quantity[\"maximum_per_year\"]\n",
    "quantity[\"annual_m3\"] = quantity[\"annual_m3\"].fillna(quantity[\"maximum_per_month\"] * 12)\n",
    "quantity[\"annual_m3\"] = quantity[\"annual_m3\"].fillna(quantity[\"maximum_per_day\"] * 365)\n",
    "quantity[\"annual_m3\"] = quantity[\"annual_m3\"].fillna(quantity[\"maximum_per_hour\"] * 24 * 365)\n",
    "quantity[\"annual_m3\"] = quantity[\"annual_m3\"].fillna(0.0)\n",
    "quantity[\"annual_m3\"] = quantity[\"annual_m3\"].clip(lower=0)\n",
    "\n",
    "# Link licence -> facility\n",
    "licence[\"licence_groundwater_usage_pk\"] = pd.to_numeric(licence[\"licence_groundwater_usage_pk\"], errors=\"coerce\")\n",
    "licence[\"groundwater_usage_facility_fk\"] = pd.to_numeric(licence[\"groundwater_usage_facility_fk\"], errors=\"coerce\")\n",
    "quantity[\"licence_groundwater_usage_fk\"] = pd.to_numeric(quantity[\"licence_groundwater_usage_fk\"], errors=\"coerce\")\n",
    "\n",
    "q_licence = quantity.groupby(\"licence_groundwater_usage_fk\", as_index=False)[\"annual_m3\"].sum()\n",
    "q_facility = (\n",
    "    licence.merge(q_licence, left_on=\"licence_groundwater_usage_pk\", right_on=\"licence_groundwater_usage_fk\", how=\"left\")\n",
    "    .groupby(\"groundwater_usage_facility_fk\", as_index=False)[\"annual_m3\"].sum()\n",
    ")\n",
    "q_facility[\"annual_m3\"] = q_facility[\"annual_m3\"].fillna(0.0)\n",
    "\n",
    "# Validity cleaning and aggregation\n",
    "validity[\"groundwater_usage_facility_fk\"] = pd.to_numeric(validity[\"groundwater_usage_facility_fk\"], errors=\"coerce\")\n",
    "validity[\"start_validity\"] = pd.to_datetime(validity[\"start_validity\"], errors=\"coerce\")\n",
    "validity[\"end_validity\"] = pd.to_datetime(validity[\"end_validity\"], errors=\"coerce\")\n",
    "\n",
    "validity.loc[validity[\"start_validity\"].dt.year < 1900, \"start_validity\"] = pd.Timestamp(\"1900-01-01\")\n",
    "validity.loc[validity[\"end_validity\"].dt.year > 2100, \"end_validity\"] = pd.Timestamp(\"2100-12-31\")\n",
    "\n",
    "validity[\"start_validity\"] = validity[\"start_validity\"].fillna(pd.Timestamp(\"1900-01-01\"))\n",
    "validity[\"end_validity\"] = validity[\"end_validity\"].fillna(pd.Timestamp(\"2100-12-31\"))\n",
    "\n",
    "validity_facility = validity.groupby(\"groundwater_usage_facility_fk\", as_index=False).agg(\n",
    "    valid_start=(\"start_validity\", \"min\"),\n",
    "    valid_end=(\"end_validity\", \"max\"),\n",
    ")\n",
    "\n",
    "# Merge facility geometry + quantity + validity\n",
    "facilities[\"groundwater_usage_facility_pk\"] = pd.to_numeric(facilities[\"groundwater_usage_facility_pk\"], errors=\"coerce\")\n",
    "facilities = facilities.merge(\n",
    "    q_facility,\n",
    "    left_on=\"groundwater_usage_facility_pk\",\n",
    "    right_on=\"groundwater_usage_facility_fk\",\n",
    "    how=\"left\",\n",
    ")\n",
    "facilities = facilities.merge(\n",
    "    validity_facility,\n",
    "    left_on=\"groundwater_usage_facility_pk\",\n",
    "    right_on=\"groundwater_usage_facility_fk\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "facilities[\"annual_m3\"] = facilities[\"annual_m3\"].fillna(0.0)\n",
    "facilities[\"valid_start\"] = facilities[\"valid_start\"].fillna(pd.Timestamp(\"1900-01-01\"))\n",
    "facilities[\"valid_end\"] = facilities[\"valid_end\"].fillna(pd.Timestamp(\"2100-12-31\"))\n",
    "\n",
    "# MultiPoint -> Point rows\n",
    "facilities = facilities.explode(index_parts=False, ignore_index=True)\n",
    "facilities = facilities[facilities.geometry.notna()].copy()\n",
    "\n",
    "# Keep ZH bbox and positive quantity only\n",
    "facilities_zh = facilities.cx[minx:maxx, miny:maxy].copy()\n",
    "facilities_zh = facilities_zh[facilities_zh[\"annual_m3\"] > 0].copy()\n",
    "\n",
    "print(\"Facilities in ZH with positive annual quantity:\", len(facilities_zh))\n",
    "print(facilities_zh[[\"groundwater_usage_facility_pk\", \"annual_m3\", \"valid_start\", \"valid_end\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c53e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site-facility pairs: 25488\n",
      "Monthly pumping rows: 91183\n",
      "   site_id      month  pumping_m3_month\n",
      "0     9708 2010-01-01           68525.0\n",
      "1     9708 2010-02-01           68525.0\n",
      "2     9708 2010-03-01           68525.0\n",
      "3     9708 2010-04-01           68525.0\n",
      "4     9708 2010-05-01           68525.0\n"
     ]
    }
   ],
   "source": [
    "# Spatial join: site buffer (5 km) and facility points\n",
    "BUFFER_METERS = 5000\n",
    "\n",
    "sites_m = sites_zh[[\"site_id\", \"geometry\"]].to_crs(28992)\n",
    "facilities_m = facilities_zh[[\n",
    "    \"groundwater_usage_facility_pk\",\n",
    "    \"annual_m3\",\n",
    "    \"valid_start\",\n",
    "    \"valid_end\",\n",
    "    \"geometry\",\n",
    "]].to_crs(28992)\n",
    "\n",
    "site_buffers = sites_m.copy()\n",
    "site_buffers[\"geometry\"] = site_buffers.geometry.buffer(BUFFER_METERS)\n",
    "\n",
    "pairs = gpd.sjoin(\n",
    "    facilities_m,\n",
    "    site_buffers[[\"site_id\", \"geometry\"]],\n",
    "    how=\"inner\",\n",
    "    predicate=\"within\",\n",
    ")\n",
    "\n",
    "pairs = pairs[[\"groundwater_usage_facility_pk\", \"site_id\", \"annual_m3\", \"valid_start\", \"valid_end\"]]\n",
    "pairs = pairs.drop_duplicates(subset=[\"groundwater_usage_facility_pk\", \"site_id\"]).copy()\n",
    "\n",
    "pairs[\"valid_start\"] = pd.to_datetime(pairs[\"valid_start\"], errors=\"coerce\").dt.to_period(\"M\").dt.to_timestamp()\n",
    "pairs[\"valid_end\"] = pd.to_datetime(pairs[\"valid_end\"], errors=\"coerce\").dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "pairs[\"valid_start\"] = pairs[\"valid_start\"].fillna(pd.Timestamp(\"1900-01-01\"))\n",
    "pairs[\"valid_end\"] = pairs[\"valid_end\"].fillna(pd.Timestamp(\"2100-12-01\"))\n",
    "\n",
    "# Expand pairs to month and keep active months only\n",
    "months_df = pd.DataFrame({\"month\": MONTHS})\n",
    "months_df[\"_k\"] = 1\n",
    "pairs[\"_k\"] = 1\n",
    "pair_month = pairs.merge(months_df, on=\"_k\", how=\"inner\").drop(columns=[\"_k\"])\n",
    "\n",
    "pair_month = pair_month[\n",
    "    (pair_month[\"month\"] >= pair_month[\"valid_start\"])\n",
    "    & (pair_month[\"month\"] <= pair_month[\"valid_end\"])\n",
    "].copy()\n",
    "\n",
    "pair_month[\"pumping_m3_month\"] = pair_month[\"annual_m3\"] / 12.0\n",
    "\n",
    "pumping_df = (\n",
    "    pair_month.groupby([\"site_id\", \"month\"], as_index=False)[\"pumping_m3_month\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "print(\"Site-facility pairs:\", len(pairs))\n",
    "print(\"Monthly pumping rows:\", len(pumping_df))\n",
    "print(pumping_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5034d",
   "metadata": {},
   "source": [
    "## Build final panel and save\n",
    "\n",
    "Output:\n",
    "- `Data/processed/zh_monthly_features.parquet`\n",
    "- `Data/processed/zh_sites.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d2cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- /Users/izhan/Desktop/groundwater/stephanie_thesis_groundwater/Data/processed/zh_monthly_features.parquet\n",
      "- /Users/izhan/Desktop/groundwater/stephanie_thesis_groundwater/Data/processed/zh_sites.parquet\n",
      "Panel shape: (124608, 19)\n",
      "   site_id      month  number  latitude  longitude expver     tp_mm    pet_mm  \\\n",
      "0     9708 2010-01-01       0      52.2        5.1   0001  1.420961  0.474006   \n",
      "1     9708 2010-02-01       0      52.2        5.1   0001  3.182507  1.163788   \n",
      "2     9708 2010-03-01       0      52.2        5.1   0001  2.071045  2.689257   \n",
      "3     9708 2010-04-01       0      52.2        5.1   0001  1.068072  4.618317   \n",
      "4     9708 2010-05-01       0      52.2        5.1   0001  2.236217  4.809119   \n",
      "\n",
      "       t2m_c    spi3_z  spi6_z  spi12_z  pumping_m3_month  well_id       lon  \\\n",
      "0  -0.712128       NaN     NaN      NaN           68525.0     8538  5.067566   \n",
      "1   1.336090       NaN     NaN      NaN           68525.0     8538  5.067566   \n",
      "2   5.780853 -0.071914     NaN      NaN           68525.0     8538  5.067566   \n",
      "3   8.914948 -0.249203     NaN      NaN           68525.0     8538  5.067566   \n",
      "4  10.153137 -0.724613     NaN      NaN           68525.0     8538  5.067566   \n",
      "\n",
      "         lat  max_observations first_date  last_date  \n",
      "0  52.240898               158 1997-09-15 2025-10-01  \n",
      "1  52.240898               158 1997-09-15 2025-10-01  \n",
      "2  52.240898               158 1997-09-15 2025-10-01  \n",
      "3  52.240898               158 1997-09-15 2025-10-01  \n",
      "4  52.240898               158 1997-09-15 2025-10-01  \n"
     ]
    }
   ],
   "source": [
    "# Build site-month skeleton\n",
    "panel = pd.MultiIndex.from_product(\n",
    "    [sites_zh[\"site_id\"].astype(int).unique(), MONTHS],\n",
    "    names=[\"site_id\", \"month\"],\n",
    ").to_frame(index=False)\n",
    "\n",
    "# Merge features\n",
    "panel = panel.merge(meteo_df, on=[\"site_id\", \"month\"], how=\"left\")\n",
    "panel = panel.merge(pumping_df, on=[\"site_id\", \"month\"], how=\"left\")\n",
    "panel[\"pumping_m3_month\"] = panel[\"pumping_m3_month\"].fillna(0.0)\n",
    "\n",
    "# Add static site metadata\n",
    "site_meta = sites_zh[[\n",
    "    \"site_id\", \"well_id\", \"lon\", \"lat\", \"max_observations\", \"first_date\", \"last_date\"\n",
    "]].copy()\n",
    "site_meta[\"site_id\"] = site_meta[\"site_id\"].astype(int)\n",
    "\n",
    "panel = panel.merge(site_meta, on=\"site_id\", how=\"left\")\n",
    "\n",
    "# Save\n",
    "out_dir = ROOT / \"Data\" / \"processed\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "panel_path = out_dir / \"zh_monthly_features.parquet\"\n",
    "sites_path = out_dir / \"zh_sites.parquet\"\n",
    "\n",
    "saved_main = None\n",
    "saved_meta = None\n",
    "\n",
    "try:\n",
    "    panel.to_parquet(panel_path, index=False)\n",
    "    site_meta.to_parquet(sites_path, index=False)\n",
    "    saved_main = panel_path\n",
    "    saved_meta = sites_path\n",
    "except Exception:\n",
    "    panel_path = out_dir / \"zh_monthly_features.pkl\"\n",
    "    sites_path = out_dir / \"zh_sites.pkl\"\n",
    "    panel.to_pickle(panel_path)\n",
    "    site_meta.to_pickle(sites_path)\n",
    "    saved_main = panel_path\n",
    "    saved_meta = sites_path\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", saved_main)\n",
    "print(\"-\", saved_meta)\n",
    "print(\"Panel shape:\", panel.shape)\n",
    "print(panel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04894bc",
   "metadata": {},
   "source": [
    "## to do next\n",
    "\n",
    "Build the target variable \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
